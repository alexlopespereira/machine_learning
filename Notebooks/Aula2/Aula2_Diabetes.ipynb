{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexlopespereira/machine_learning/blob/main/Notebooks/Aula2/Aula2_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-I3lZWgg0BI"
      },
      "source": [
        "# Classificação de Diabetes com o Dataset Pima Indians Diabetes\n",
        "\n",
        "Neste notebook, utilizaremos o dataset Pima Indians Diabetes para construir um classificador de rede neural utilizando o `MLPClassifier` do scikit-learn. O fluxo do notebook inclui:\n",
        "- Carregamento do dataset\n",
        "- Preparação dos dados\n",
        "- Pré-processamento (padronização)\n",
        "- Treinamento do modelo\n",
        "- Avaliação dos resultados"
      ],
      "id": "j-I3lZWgg0BI"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8KyPw1mmg0BO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "id": "8KyPw1mmg0BO",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P9PIGfOg0BR"
      },
      "source": [
        "## Carregamento do Dataset\n",
        "\n",
        "Utilizaremos o `fetch_openml` para carregar o dataset \"PimaIndiansDiabetes\". Esse dataset contém 768 amostras com 8 atributos numéricos e uma coluna alvo que indica se o paciente é diabético (1) ou não (0)."
      ],
      "id": "4P9PIGfOg0BR"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EXoaXe13g0BS",
        "outputId": "5d0d523d-b303-4818-c0d6-1c7f79463ef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Carrega o dataset Pima Indians Diabetes\n",
        "pima = fetch_openml(name='diabetes', as_frame=True)\n",
        "df = pima.frame\n",
        "\n",
        "# Exibe as primeiras linhas do dataset\n",
        "print(df.head())"
      ],
      "id": "EXoaXe13g0BS",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_openml.py:323: UserWarning: Multiple active versions of the dataset matching the name diabetes exist. Versions may be fundamentally different, returning version 1. Available versions:\n",
            "- version 1, status: active\n",
            "  url: https://www.openml.org/search?type=data&id=37\n",
            "- version 5, status: active\n",
            "  url: https://www.openml.org/search?type=data&id=42608\n",
            "\n",
            "  warn(warning_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
            "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
            "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
            "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
            "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
            "4     0   137    40    35   168  43.1  2.288   33  tested_positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1npKogdg0BU"
      },
      "source": [
        "## Preparação dos Dados\n",
        "\n",
        "Neste passo, separamos as features (atributos) da variável alvo e realizamos a divisão dos dados em conjuntos de treino e teste. Utilizaremos 80% dos dados para treino e 20% para teste, mantendo a proporção das classes com o parâmetro `stratify`."
      ],
      "id": "E1npKogdg0BU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfzft-31g0BV"
      },
      "source": [
        "# Separa as features e a variável alvo\n",
        "X = df.drop(columns='class')\n",
        "#y = df['class'].astype(int)\n",
        "# O código acima não funciona porque a coluna class contem as strings tested_positive e tested_negative. Converta esta coluna para inteiro (0 ou 1) e guarde o resultado na variavel y\n",
        "\n",
        "# Divide os dados em treino (80%) e teste (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "id": "jfzft-31g0BV",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjYbe0Thg0BV"
      },
      "source": [
        "## Pré-processamento: Padronização\n",
        "\n",
        "Como todas as colunas são numéricas, utilizamos o `StandardScaler` para padronizar os dados. Essa técnica transforma as features para terem média 0 e desvio padrão 1, o que pode ajudar na convergência do modelo."
      ],
      "id": "qjYbe0Thg0BV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aMV3KrMg0BW"
      },
      "source": [
        "# Inicializa e ajusta o StandardScaler nos dados de treino\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "id": "3aMV3KrMg0BW",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5ZvQaOeg0BZ"
      },
      "source": [
        "## Definição e Treinamento do Modelo\n",
        "\n",
        "Utilizaremos o `MLPClassifier` do scikit-learn para construir uma rede neural com duas camadas ocultas. As camadas terão 64 e 32 neurônios, respectivamente. Configuramos a função de ativação `relu`, o solver `adam` e ativamos o early stopping para prevenir overfitting."
      ],
      "id": "Q5ZvQaOeg0BZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6bclgL1g0Be"
      },
      "source": [
        "model = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      max_iter=200,\n",
        "                      random_state=42,\n",
        "                      early_stopping=True)\n",
        "\n",
        "# Treina o modelo com os dados padronizados\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "id": "V6bclgL1g0Be",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy4wO4fXg0Bi"
      },
      "source": [
        "## Avaliação do Modelo\n",
        "\n",
        "Após o treinamento, avaliamos o desempenho do modelo utilizando o conjunto de teste. Calculamos a acurácia e geramos um relatório de classificação detalhado (precisão, recall, f1-score)."
      ],
      "id": "xy4wO4fXg0Bi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exudcOSFg0Bl"
      },
      "source": [
        "# Realiza as previsões no conjunto de teste\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calcula a acurácia do modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n",
        "\n",
        "# Exibe o relatório de classificação\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "id": "exudcOSFg0Bl",
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}