{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Classificação de Diabetes com o Dataset Pima Indians Diabetes\n",
       "\n",
       "Neste notebook, utilizaremos o dataset Pima Indians Diabetes para construir um classificador de rede neural utilizando o `MLPClassifier` do scikit-learn. O fluxo do notebook inclui:\n",
       "- Carregamento do dataset\n",
       "- Preparação dos dados\n",
       "- Pré-processamento (padronização)\n",
       "- Treinamento do modelo\n",
       "- Avaliação dos resultados"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.datasets import fetch_openml\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.metrics import classification_report, accuracy_score"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Carregamento do Dataset\n",
       "\n",
       "Utilizaremos o `fetch_openml` para carregar o dataset \"PimaIndiansDiabetes\". Esse dataset contém 768 amostras com 8 atributos numéricos e uma coluna alvo que indica se o paciente é diabético (1) ou não (0)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Carrega o dataset Pima Indians Diabetes\n",
       "pima = fetch_openml(name='PimaIndiansDiabetes', version=1, as_frame=True)\n",
       "df = pima.frame\n",
       "\n",
       "# Exibe as primeiras linhas do dataset\n",
       "print(df.head())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Preparação dos Dados\n",
       "\n",
       "Neste passo, separamos as features (atributos) da variável alvo e realizamos a divisão dos dados em conjuntos de treino e teste. Utilizaremos 80% dos dados para treino e 20% para teste, mantendo a proporção das classes com o parâmetro `stratify`."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Separa as features e a variável alvo\n",
       "X = df.drop(columns='class')\n",
       "y = df['class'].astype(int)  # Converte a coluna alvo para inteiro (0 ou 1)\n",
       "\n",
       "# Divide os dados em treino (80%) e teste (20%)\n",
       "X_train, X_test, y_train, y_test = train_test_split(\n",
       "    X, y, test_size=0.2, random_state=42, stratify=y\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Pré-processamento: Padronização\n",
       "\n",
       "Como todas as colunas são numéricas, utilizamos o `StandardScaler` para padronizar os dados. Essa técnica transforma as features para terem média 0 e desvio padrão 1, o que pode ajudar na convergência do modelo."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Inicializa e ajusta o StandardScaler nos dados de treino\n",
       "scaler = StandardScaler()\n",
       "X_train_scaled = scaler.fit_transform(X_train)\n",
       "X_test_scaled = scaler.transform(X_test)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Definição e Treinamento do Modelo\n",
       "\n",
       "Utilizaremos o `MLPClassifier` do scikit-learn para construir uma rede neural com duas camadas ocultas. As camadas terão 64 e 32 neurônios, respectivamente. Configuramos a função de ativação `relu`, o solver `adam` e ativamos o early stopping para prevenir overfitting."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "model = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
       "                      activation='relu',\n",
       "                      solver='adam',\n",
       "                      max_iter=200,\n",
       "                      random_state=42,\n",
       "                      early_stopping=True)\n",
       "\n",
       "# Treina o modelo com os dados padronizados\n",
       "model.fit(X_train_scaled, y_train)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Avaliação do Modelo\n",
       "\n",
       "Após o treinamento, avaliamos o desempenho do modelo utilizando o conjunto de teste. Calculamos a acurácia e geramos um relatório de classificação detalhado (precisão, recall, f1-score)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Realiza as previsões no conjunto de teste\n",
       "y_pred = model.predict(X_test_scaled)\n",
       "\n",
       "# Calcula a acurácia do modelo\n",
       "accuracy = accuracy_score(y_test, y_pred)\n",
       "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n",
       "\n",
       "# Exibe o relatório de classificação\n",
       "print(classification_report(y_test, y_pred))"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python",
      "version": "3.x"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   